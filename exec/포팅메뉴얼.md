# 서비스 버전 정보

| Ubuntu | Ubuntu 20.04.6 LTS |
| --- | --- |
| Java | Correto-17 java version “17.0.10” |
| Spring Boot | 3.0.0 |
| Gradle | Gradle-7.4-bin |
| Redis | 7.2.4 |
| Nginx | Nginx/1.23.3 |
| Openvidu | 2.29.0 |
| Jenkins | 2.441 |
| Jenkins Java | Jdk17 |
| Maria DB | 10.3.23-MariaDB |
| Docker Version | Docker Engine – Community 25.0.0 |
| Docker API Version | 1.44 |
| Docker compose | 1.29.2 |
| Node | V20.10.0 |
| Npm | 10.2.3 |
| Vue | vue@3.4.15 |
| Vuetify | vuetify@3.5.1 |

# 서버 설정

서버는 Amazon Lightsail을 이용했으며, 서버 스펙은 아래와 같다.

```jsx
16GB 메모리
vCPU 4개
320GB SSD 디스크
6TB 전송
```

## 우분투 서버 기본 설정

### 우분투 서버 시간 설정

 한국시간으로 서버 시간 변경

```jsx
sudo timedatectl set-timezone Asia/Seoul
```

### 미러 서버 설정

패키지 갱신/다운로드 속도 향상을 위해 국내망인 카카오 미러 서버로 설정 

```jsx
sudo sed -i 's/ap-northeast-2.ec2.archive.ubuntu.com/mirror.kakao.com/g' /etc/apt/sources.list
```

### 패키지 목록 업데이트 & 패키지 업데이트

```jsx
sudo apt-get -y update && sudo apt-get -y upgrade
```

### Swap 영역 할당

용량 확인

```jsx
free -h
```

스왑 영역 할당

```jsx
sudo fallocate -l 4G /swapfile
```

swapfile 권한 수정

```jsx
sudo chmod 600 /swapfile
```

swapfile 생성

```jsx
sudo mkswap /swapfile
```

swapfile 활성화

```jsx
sudo swapon /swapfile
```

시스템 재부팅 되어도 swap 유지 할 수 있도록 설정

```jsx
sudo echo '/swapfile none swap sw 0 0' | sudo tee -a /etc/fstab
```

# Jenkins 설정

## Jenkins Docker Container 설정

Jenkins의 경우 배포 할 때마다 실행될 필요는 없기 때문에, docker-compose 내에 구성하지 않고 독립적으로 수행되게 한다.

```jsx
docker run -d --env JENKINS_OPTS=--httpPort=8080 -v /etc/localtime:/etc/localtime:ro -e TZ=Asia/Seoul -p 8080:8080 -v /jenkins:/var/jenkins_home -v /var/run/docker.sock:/var/run/docker.sock -v /usr/local/bin/docker-compose:/usr/local/bin/docker-compose --name jenkins -u root jenkins/jenkins:jdk17
```

## Jenkins 컨테이너 접속

```jsx
docker exec -it jenkins /bin/bash
```

## Docker Repository 등록 및 docker-ce 패키지 설치

```jsx
apt-get update && apt-get -y install apt-transport-https ca-certificates curl gnupg2 software-properties-common && curl -fsSL https://download.docker.com/linux/$(. /etc/os-release; echo "$ID")/gpg > /tmp/dkey; apt-key add /tmp/dkey && add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/$(. /etc/os-release; echo "$ID") $(lsb_release -cs) stable" && apt-get update && apt-get -y install docker-ce
```

## Jenkins 초기 비밀번호 확인

초기 비밀번호 확인하여 http://i10a802.p.ssafy.io:8080 접속하여 기본 세팅 해주면 된다.

```jsx
cat /var/lib/jenkins/secrets/initialAdminPassword
```

## Jenkins 플러그인 설치 목록

```jsx
# ssh 커맨드 입력에 사용
SSH Agent

# docker 이미지 생성에 사용
Docker
Docker Commons
Docker Pipeline
Docker API

# 웹훅을 통해 브랜치 merge request 이벤트 발생시 Jenkins 자동 빌드에 사용
Generic Webhook Trigger

# 타사 레포지토리 이용시 사용 (GitLab, Github 등)
GitLab
GitLab API
GitLab Authentication
GitHub Authentication

# Node.js 빌드시 사용
NodeJS
```

## 빌드 Credential 정보

- spoparty-docker
    - dockerHub 계정 정보
- ubuntu-a802
    - ssh 인증 pem키
- spoparty-jenkins
    - gitlab API 토큰
- gitlab-eunbyeol
    - git clone에 사용될 계정
- application-private
    - backend CI,CD 프로세스에 사용될 application-private 파일
- batch-application-private
    - batch CI,CD 프로세스에 사용될  application-private 파일

## Credential 파일 정보

### application-private.yml (backend)

```jsx
# Datasource
spring:
  config:
    activate:
      on-profile: private
  datasource:
    hikari:
      driver-class-name: org.mariadb.jdbc.Driver
      #      username: admin
      #      password: ssafya802
      #    url: jdbc:mariadb://spoparty-database.cpqorrmhxcvs.ap-northeast-2.rds.amazonaws.com:3306/spoparty?serverTimezone=UTC&useUnicode=true&characterEncoding=utf8
      username: S10P12A802
      password: 6DcwoD2dA
    url: jdbc:mariadb://stg-yswa-kr-practice-db-master.mariadb.database.azure.com:3306/S10P12A802?serverTimezone=UTC&useUnicode=true&characterEncoding=utf8

  # Smtp
  mail:
    host: smtp.gmail.com
    port: 587
    username: spoparty123@gmail.com
    password: tjbp bgca mree laud
    properties:
      mail:
        smtp:
          auth: true # Autentication
          timeout: 5000 # Socket Read Timeout (ms)
          starttls:
            enable: true # StartTLS

  # OAuth2 kakao
  security:
    oauth2:
      client:
        provider:
          kakao:
            authorization-uri: https://kauth.kakao.com/oauth/authorize
            token-uri: https://kauth.kakao.com/oauth/token
            user-info-uri: https://kapi.kakao.com/v2/user/me
            user-name-attribute: id
        registration:
          kakao:
            client-id: e6eaf57a86c5a93933a23dd63e73c44e
            client-secret: bTZG4U0KETlDHaeaLuQEqpnuaNoC6wvZ
            redirect-uri: https://i10a802.p.ssafy.io/api/login/oauth2/code/kakao
            authorization-grant-type: authorization_code
            client-authentication-method: POST
            client-name: Kakao
            scope:
              - profile_nickname
              - profile_image
              - account_email

# Smtp mail content
smtp:
  mail:
    subject: "SPOPARTY 이메일 인증"
    prefix: "# 인증번호 : "
    suffix: "\n 5분안에 입력해주세요"

# Jwt 1hour / 15day
jwt:
  access:
    secret: dyAeHub00pwL4F2Lcse52l1z5A003L3Bjtw4lcq751tymZvvqkcEU7L1imkKHeDa
    expiration: 3600000
  refresh:
    secret: syLzLe230fFXO0OfYB6XEQoEj1QzRlVgtjNL8PYs1A1tymCL1ctob5dlwoqhvhDa
    expiration: 1269600000

# S3
cloud:
  aws:
    s3:
      bucket: spoparty-bucket
    stack.auto: false
    region.static: ap-northeast-2
    credentials:
      accessKey: AKIATT55DVO6CEBMVMWS
      secretKey: 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

openvidu:
  url: https://i10a802.p.ssafy.io/
  secret: MY_SECRET

club:
  invite:
    url:
      domain: https://i10a802.p.ssafy.io/invite/
      delimiter: _
    expirationDay: 7
```

### application-private.yml (batch)

```jsx
spring:
  meta:
    datasource:
      # 메타 정보 저장 DB
      hikari:
        username: admin
        password: ssafya802
        driver-class-name: org.mariadb.jdbc.Driver
        pool-name: 'meta-data-pool'
        jdbcurl: jdbc:mariadb://spoparty-batch-db.ctm6ms0ey3dl.ap-northeast-2.rds.amazonaws.com:3306/spoparty_batch_db?serverTimezone=UTC&useUnicode=true&characterEncoding=utf8
    # 처리 데이터 소스
  default:
    datasource:
      hikari:
        #        username: admin
        #        password: ssafya802
        #        driver-class-name: org.mariadb.jdbc.Driver
        #        pool-name: 'read-and-write-pool'
        #        jdbcurl: jdbc:mariadb://spoparty-database.cpqorrmhxcvs.ap-northeast-2.rds.amazonaws.com:3306/spoparty?serverTimezone=UTC&useUnicode=true&characterEncoding=utf8
        username: S10P12A802
        password: 6DcwoD2dA
        driver-class-name: org.mariadb.jdbc.Driver
        pool-name: 'read-and-write-pool'
        jdbcurl: jdbc:mariadb://stg-yswa-kr-practice-db-master.mariadb.database.azure.com:3306/S10P12A802?serverTimezone=UTC&useUnicode=true&characterEncoding=utf8

api-key: 95920a4c5a228f3edfd581cf9cd299a8
api-host: v3.football.api-sports.io
base-url: https://v3.football.api-sports.io

lang-secret: uBDc7x2dwu
lang-id: xCLhObLuJ8ob43b93ziu
lang-base-url: https://openapi.naver.com/v1/papago/n2mt
```

# 방화벽 설정

SPOPARTY 레포지토리 Readme 파일의 EC2 포트 정리 항목을 참고하여 설정해준다 

[](https://lab.ssafy.com/s10-webmobile1-sub2/S10P12A802)

### ufw 상태 확인

```jsx
sudo ufw status
```

### 사용할 포트 허용하기

```jsx
sudo ufw allow {portNumber}
```

### 등록한 포트 조회하기

```jsx
sudo ufw show added
```

### ufw 활성화 하기

```jsx
sudo ufw enabled
```

### ufw 포트 삭제하기

```jsx
sudo ufw delete {number}
```

### ufw 정책 삭제 후 적용하기

**삭제한 정책은 반드시 enable을 수행해야 적용된다.**

```jsx
sudo ufw enabled
```

### ufw 끄기

```jsx
sudo ufw disable
```

# Openvidu 설정

### Openvidu 설치

아래의 Openvidu Docs를 참고하여 오픈비두 설치

[On premises - OpenVidu Docs](https://docs.openvidu.io/en/stable/deployment/ce/on-premises/)

### 관리자 권한 부여

```jsx
sudo su
```

### opt 폴더로 이동

```jsx
cd /opt
```

### Openvidu 인스톨

```jsx
curl https://s3-eu-west-1.amazonaws.com/aws.openvidu.io/install_openvidu_latest.sh | bash
```

### Openvidu env 파일 수정

```jsx
vim /opt/openvidu/.env
```

```jsx
# OpenVidu configuration
# ----------------------
# Documentation: https://docs.openvidu.io/en/stable/reference-docs/openvidu-config/

# NOTE: This file doesn't need to quote assignment values, like most shells do.
# All values are stored as-is, even if they contain spaces, so don't quote them.

# Domain name. If you do not have one, the public IP of the machine.
# For example: 198.51.100.1, or openvidu.example.com
DOMAIN_OR_PUBLIC_IP=i10a802.p.ssafy.io

# OpenVidu SECRET used for apps to connect to OpenVidu server and users to access to OpenVidu Dashboard
OPENVIDU_SECRET=MY_SECRET

# Certificate type:
# - selfsigned:  Self signed certificate. Not recommended for production use.
#                Users will see an ERROR when connected to web page.
# - owncert:     Valid certificate purchased in a Internet services company.
#                Please put the certificates files inside folder ./owncert
#                with names certificate.key and certificate.cert
# - letsencrypt: Generate a new certificate using letsencrypt. Please set the
#                required contact email for Let's Encrypt in LETSENCRYPT_EMAIL
#                variable.
CERTIFICATE_TYPE=letsencrypt

# If CERTIFICATE_TYPE=letsencrypt, you need to configure a valid email for notifications
LETSENCRYPT_EMAIL=gogoadl@naver.com

# Proxy configuration
# If you want to change the ports on which openvidu listens, uncomment the following lines

# Allows any request to http://DOMAIN_OR_PUBLIC_IP:HTTP_PORT/ to be automatically
# redirected to https://DOMAIN_OR_PUBLIC_IP:HTTPS_PORT/.
# WARNING: the default port 80 cannot be changed during the first boot
# if you have chosen to deploy with the option CERTIFICATE_TYPE=letsencrypt
# HTTP_PORT=80

# Changes the port of all services exposed by OpenVidu.
# SDKs, REST clients and browsers will have to connect to this port
# HTTPS_PORT=9091

# Old paths are considered now deprecated, but still supported by default.
# OpenVidu Server will log a WARN message every time a deprecated path is called, indicating
# the new path that should be used instead. You can set property SUPPORT_DEPRECATED_API=false
# to stop allowing the use of old paths.
# Default value is true
# SUPPORT_DEPRECATED_API=false

# If true request to with www will be redirected to non-www requests
# Default value is false
# REDIRECT_WWW=false

# How many workers to configure in nginx proxy.
# The more workers, the more requests will be handled
# Default value is 10240
# WORKER_CONNECTIONS=10240

# Access restrictions
# In this section you will be able to restrict the IPs from which you can access to
# Openvidu API and the Administration Panel
# WARNING! If you touch this configuration you can lose access to the platform from some IPs.
# Use it carefully.

# This section limits access to the /dashboard (OpenVidu CE) and /inspector (OpenVidu Pro) pages.
# The form for a single IP or an IP range is:
# ALLOWED_ACCESS_TO_DASHBOARD=198.51.100.1 and ALLOWED_ACCESS_TO_DASHBOARD=198.51.100.0/24
# To limit multiple IPs or IP ranges, separate by commas like this:
# ALLOWED_ACCESS_TO_DASHBOARD=198.51.100.1, 198.51.100.0/24
# ALLOWED_ACCESS_TO_DASHBOARD=

# This section limits access to the Openvidu REST API.
# The form for a single IP or an IP range is:
# ALLOWED_ACCESS_TO_RESTAPI=198.51.100.1 and ALLOWED_ACCESS_TO_RESTAPI=198.51.100.0/24
# To limit multiple IPs or or IP ranges, separate by commas like this:
# ALLOWED_ACCESS_TO_RESTAPI=198.51.100.1, 198.51.100.0/24
# ALLOWED_ACCESS_TO_RESTAPI=

# Whether to enable recording module or not
OPENVIDU_RECORDING=true

# Use recording module with debug mode.
OPENVIDU_RECORDING_DEBUG=true

# Openvidu Folder Record used for save the openvidu recording videos. Change it
# with the folder you want to use from your host.
OPENVIDU_RECORDING_PATH=/opt/openvidu/recordings

# System path where OpenVidu Server should look for custom recording layouts
OPENVIDU_RECORDING_CUSTOM_LAYOUT=/opt/openvidu/custom-layout

# if true any client can connect to
# https://OPENVIDU_SERVER_IP:OPENVIDU_PORT/recordings/any_session_file.mp4
# and access any recorded video file. If false this path will be secured with
# OPENVIDU_SECRET param just as OpenVidu Server dashboard at
# https://OPENVIDU_SERVER_IP:OPENVIDU_PORT
# Values: true | false
OPENVIDU_RECORDING_PUBLIC_ACCESS=false

# Which users should receive the recording events in the client side
# (recordingStarted, recordingStopped). Can be all (every user connected to
# the session), publisher_moderator (users with role 'PUBLISHER' or
# 'MODERATOR'), moderator (only users with role 'MODERATOR') or none
# (no user will receive these events)
OPENVIDU_RECORDING_NOTIFICATION=publisher_moderator

# Timeout in seconds for recordings to automatically stop (and the session involved to be closed)
# when conditions are met: a session recording is started but no user is publishing to it or a session
# is being recorded and last user disconnects. If a user publishes within the timeout in either case,
# the automatic stop of the recording is cancelled
# 0 means no timeout
OPENVIDU_RECORDING_AUTOSTOP_TIMEOUT=60

# Maximum video bandwidth sent from clients to OpenVidu Server, in kbps.
# 0 means unconstrained
OPENVIDU_STREAMS_VIDEO_MAX_RECV_BANDWIDTH=1000

# Minimum video bandwidth sent from clients to OpenVidu Server, in kbps.
# 0 means unconstrained
OPENVIDU_STREAMS_VIDEO_MIN_RECV_BANDWIDTH=300

# Maximum video bandwidth sent from OpenVidu Server to clients, in kbps.
# 0 means unconstrained
OPENVIDU_STREAMS_VIDEO_MAX_SEND_BANDWIDTH=1000

# Minimum video bandwidth sent from OpenVidu Server to clients, in kbps.
# 0 means unconstrained
OPENVIDU_STREAMS_VIDEO_MIN_SEND_BANDWIDTH=300

# All sessions of OpenVidu will try to force this codec. If OPENVIDU_STREAMS_ALLOW_TRANSCODING=true
# when a codec can not be forced, transcoding will be allowed
# Values: MEDIA_SERVER_PREFERRED, NONE, VP8, VP9, H264
# Default value is MEDIA_SERVER_PREFERRED
# OPENVIDU_STREAMS_FORCED_VIDEO_CODEC=MEDIA_SERVER_PREFERRED

# Allow transcoding if codec specified in OPENVIDU_STREAMS_FORCED_VIDEO_CODEC can not be applied
# Values: true | false
# Default value is false
# OPENVIDU_STREAMS_ALLOW_TRANSCODING=false

# true to enable OpenVidu Webhook service. false' otherwise
# Values: true | false
OPENVIDU_WEBHOOK=false

# HTTP endpoint where OpenVidu Server will send Webhook HTTP POST messages
# Must be a valid URL: http(s)://ENDPOINT
#OPENVIDU_WEBHOOK_ENDPOINT=

# List of headers that OpenVidu Webhook service will attach to HTTP POST messages
#OPENVIDU_WEBHOOK_HEADERS=

# List of events that will be sent by OpenVidu Webhook service
# Default value is all available events
OPENVIDU_WEBHOOK_EVENTS=[sessionCreated,sessionDestroyed,participantJoined,participantLeft,webrtcConnectionCreated,webrtcConnectionDestroyed,recordingStatusChanged,filterEventDispatched,mediaNodeStatusChanged,nodeCrashed,nodeRecovered,broadcastStarted,broadcastStopped]

# How often the garbage collector of non active sessions runs.
# This helps cleaning up sessions that have been initialized through
# REST API (and maybe tokens have been created for them) but have had no users connected.
# Default to 900s (15 mins). 0 to disable non active sessions garbage collector
OPENVIDU_SESSIONS_GARBAGE_INTERVAL=900
# 디폴트 900 !!
# Minimum time in seconds that a non active session must have been in existence
# for the garbage collector of non active sessions to remove it. Default to 3600s (1 hour).
# If non active sessions garbage collector is disabled
# (property 'OPENVIDU_SESSIONS_GARBAGE_INTERVAL' to 0) this property is ignored
OPENVIDU_SESSIONS_GARBAGE_THRESHOLD=3600
# 디폴트 3600!!

# Call Detail Record enabled
# Whether to enable Call Detail Record or not
# Values: true | false
OPENVIDU_CDR=false

# Path where the cdr log files are hosted
OPENVIDU_CDR_PATH=/opt/openvidu/cdr

# Kurento Media Server image
# --------------------------
# Docker hub kurento media server: https://hub.docker.com/r/kurento/kurento-media-server
# Uncomment the next line and define this variable with KMS image that you want use
# KMS_IMAGE=kurento/kurento-media-server:7.0.1

# Kurento Media Server Level logs
# -------------------------------
# Uncomment the next line and define this variable to change
# the verbosity level of the logs of KMS
# Documentation: https://doc-kurento.readthedocs.io/en/stable/features/logging.html
# KMS_DOCKER_ENV_GST_DEBUG=

# Openvidu Server Level logs
# --------------------------
# Uncomment the next line and define this variable to change
# the verbosity level of the logs of Openvidu Service
# RECOMENDED VALUES: INFO for normal logs DEBUG for more verbose logs
# OV_CE_DEBUG_LEVEL=INFO

# Java Options
# --------------------------
# Uncomment the next line and define this to add
# options to java command
# Documentation: https://docs.oracle.com/cd/E37116_01/install.111210/e23737/configuring_jvm.htm#OUDIG00058
# JAVA_OPTIONS=-Xms2048m -Xmx4096m -Duser.timezone=UTC
```

### Openvidu docker-compose 파일 수정

```jsx
vim /opt/openvidu/docker-compose.yml
```

```jsx
version: '3.1'

services:

    openvidu-server:
        image: openvidu/openvidu-server:2.29.0
        restart: on-failure
        network_mode: host
        entrypoint: ['/usr/local/bin/entrypoint.sh']
        volumes:
            - ./coturn:/run/secrets/coturn
            - /var/run/docker.sock:/var/run/docker.sock
            - ${OPENVIDU_RECORDING_PATH}:${OPENVIDU_RECORDING_PATH}
            - ${OPENVIDU_RECORDING_CUSTOM_LAYOUT}:${OPENVIDU_RECORDING_CUSTOM_LAYOUT}
            - ${OPENVIDU_CDR_PATH}:${OPENVIDU_CDR_PATH}
        env_file:
            - .env
        environment:
            - SERVER_SSL_ENABLED=false
            - SERVER_PORT=5443
            - KMS_URIS=["ws://localhost:8888/kurento"]
            - COTURN_IP=${COTURN_IP:-auto-ipv4}
            - COTURN_PORT=${COTURN_PORT:-3478}
        logging:
            options:
                max-size: "${DOCKER_LOGS_MAX_SIZE:-100M}"

    kms:
        image: ${KMS_IMAGE:-kurento/kurento-media-server:7.0.1}
        restart: always
        network_mode: host
        ulimits:
          core: -1
        volumes:
            - /opt/openvidu/kms-crashes:/opt/openvidu/kms-crashes
            - ${OPENVIDU_RECORDING_PATH}:${OPENVIDU_RECORDING_PATH}
            - /opt/openvidu/kurento-logs:/opt/openvidu/kurento-logs
        environment:
            - KMS_MIN_PORT=40000
            - KMS_MAX_PORT=57000
            - GST_DEBUG=${KMS_DOCKER_ENV_GST_DEBUG:-}
            - KURENTO_LOG_FILE_SIZE=${KMS_DOCKER_ENV_KURENTO_LOG_FILE_SIZE:-100}
            - KURENTO_LOGS_PATH=/opt/openvidu/kurento-logs
        logging:
            options:
                max-size: "${DOCKER_LOGS_MAX_SIZE:-100M}"

    coturn:
        image: openvidu/openvidu-coturn:2.29.0
        restart: on-failure
        ports:
            - "${COTURN_PORT:-3478}:${COTURN_PORT:-3478}/tcp"
            - "${COTURN_PORT:-3478}:${COTURN_PORT:-3478}/udp"
        env_file:
            - .env
        volumes:
            - ./coturn:/run/secrets/coturn
        command:
            - --log-file=stdout
            - --listening-port=${COTURN_PORT:-3478}
            - --fingerprint
            - --min-port=${COTURN_MIN_PORT:-57001}
            - --max-port=${COTURN_MAX_PORT:-65535}
            - --realm=openvidu
            - --verbose
            - --use-auth-secret
            - --static-auth-secret=$${COTURN_SHARED_SECRET_KEY}
        logging:
            options:
                max-size: "${DOCKER_LOGS_MAX_SIZE:-100M}"

    nginx:
        image: openvidu/openvidu-proxy:2.29.0
        restart: always
        network_mode: host
        volumes:
            - ./certificates:/etc/letsencrypt
            - ./owncert:/owncert
            - ./custom-nginx-vhosts:/etc/nginx/vhost.d/
            - ./custom-nginx-locations:/custom-nginx-locations
            - ./custom-nginx.conf:/custom-nginx/custom-nginx.conf
            - ./nginx.conf:/etc/nginx/nginx.conf
            - ${OPENVIDU_RECORDING_CUSTOM_LAYOUT}:/opt/openvidu/custom-layout
            - /usr/share/nginx/html:/usr/share/nginx/html
        environment:
            - DOMAIN_OR_PUBLIC_IP=${DOMAIN_OR_PUBLIC_IP}
            - CERTIFICATE_TYPE=${CERTIFICATE_TYPE}
            - LETSENCRYPT_EMAIL=${LETSENCRYPT_EMAIL}
            - PROXY_HTTP_PORT=${HTTP_PORT:-}
            - PROXY_HTTPS_PORT=${HTTPS_PORT:-}
            - PROXY_HTTPS_PROTOCOLS=${HTTPS_PROTOCOLS:-}
            - PROXY_HTTPS_CIPHERS=${HTTPS_CIPHERS:-}
            - PROXY_HTTPS_HSTS=${HTTPS_HSTS:-}
            - ALLOWED_ACCESS_TO_DASHBOARD=${ALLOWED_ACCESS_TO_DASHBOARD:-}
            - ALLOWED_ACCESS_TO_RESTAPI=${ALLOWED_ACCESS_TO_RESTAPI:-}
            - PROXY_MODE=CE
            - WITH_APP=true
            - SUPPORT_DEPRECATED_API=${SUPPORT_DEPRECATED_API:-false}
            - REDIRECT_WWW=${REDIRECT_WWW:-false}
            - WORKER_CONNECTIONS=${WORKER_CONNECTIONS:-10240}
            - PUBLIC_IP=${PROXY_PUBLIC_IP:-auto-ipv4}
        logging:
            options:
                max-size: "${DOCKER_LOGS_MAX_SIZE:-100M}"
```

### Openvidu custom-nginx.conf 파일 수정

```jsx
vim /opt/openvidu/custom-nginx.conf
```

```jsx
# Your App
upstream yourapp {
    server localhost:9090;
}

upstream openviduserver {
    server localhost:5443;
}

server {
    listen 80;
    listen [::]:80;
    server_name i10a802.p.ssafy.io;

    # Redirect to https
    location / {
        rewrite ^(.*) https://i10a802.p.ssafy.io:443$1 permanent;
    }

    # letsencrypt
    location /.well-known/acme-challenge/ {
        root /var/www/certbot;
    }

    location /nginx_status {
        stub_status;
        allow 127.0.0.1;        #only allow requests from localhost
        deny all;               #deny all other hosts
    }
}

server {
    listen 443 ssl;
    listen [::]:443 ssl;
    server_name i10a802.p.ssafy.io;
    root /usr/share/nginx/html;
    # SSL Config
    ssl_certificate         /etc/letsencrypt/live/i10a802.p.ssafy.io/fullchain.pem;
    ssl_certificate_key     /etc/letsencrypt/live/i10a802.p.ssafy.io/privkey.pem;
    ssl_trusted_certificate /etc/letsencrypt/live/i10a802.p.ssafy.io/fullchain.pem;

    ssl_session_cache shared:SSL:50m;
    ssl_session_timeout 5m;
    ssl_stapling on;
    ssl_stapling_verify on;

    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers "ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384";
    ssl_prefer_server_ciphers off;

    add_header Strict-Transport-Security "max-age=63072000" always;

    # Proxy
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    proxy_set_header X-Forwarded-Proto https;
    proxy_headers_hash_bucket_size 512;
    proxy_redirect off;

    # Websockets
    proxy_http_version 1.1;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection "Upgrade";

    # Your App
    location / {
        root /usr/share/nginx/html;
        index index.html;
        try_files $uri $uri/ /index.html =404;
        #proxy_pass http://openviduserver; # Openvidu call by default
    }

    location /api {
        proxy_pass http://yourapp;
        proxy_set_header Connection '';
        proxy_http_version 1.1;
    }

    #location ~ /api {
#       proxy_pass http://yourapp;
#       proxy_set_header Connection '';
#       proxy_http_version 1.1;
#    }
    location /api/notifications {
        proxy_pass http://yourapp;
        proxy_set_header Connection '';
        proxy_set_header Cache-Control 'no-cache';
        proxy_set_header X-Accel-Buffering 'no';
        proxy_set_header Content-Type 'text/event-stream';
        proxy_buffering off;
        chunked_transfer_encoding on;
        proxy_read_timeout 86400s;
    }
    ########################
    # OpenVidu Locations   #
    ########################
    #################################
    # Common rules CE              #
    #################################
    # Dashboard rule
    location /dashboard {
        allow all;
        deny all;
        proxy_pass http://openviduserver;
    }

    # Websocket rule
    location ~ /openvidu$ {
        proxy_pass http://openviduserver;
    }

    #################################
    # New API                       #
    #################################
    location /openvidu/layouts {
        rewrite ^/openvidu/layouts/(.*)$ /custom-layout/$1 break;
        root /opt/openvidu;
    }

    location /openvidu/recordings {
        proxy_pass http://openviduserver;
    }

    location /openvidu/api {
        allow all;
        deny all;
        proxy_pass http://openviduserver;
    }

    location /openvidu/info {
        allow all;
        deny all;
        proxy_pass http://openviduserver;
    }

    location /openvidu/accept-certificate {
        proxy_pass http://openviduserver;
    }

    location /openvidu/cdr {
        allow all;
        deny all;
        proxy_pass http://openviduserver;
    }

    #################################
    # LetsEncrypt                   #
    #################################
    location /.well-known/acme-challenge {
        root /var/www/certbot;
        try_files $uri $uri/ =404;
    }

}
```

### Openvidu 실행

```jsx
cd /opt/openvidu

docker-compose up -d 
```

# Redis 설정

### Redis image pull

```jsx
docker pull redis
```

### Redis 컨테이너 실행

 

```jsx
docker run -p 6379:6379 redis
```

# Docker 설정

### Docker 설치 전 필요 패키지 설치

```jsx
sudo apt-get -y install apt-transport-https ca-certificates curl gnupg-agent software-properties-common
```

### GPC Key 인증 진행

```jsx
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
```

### Docker 레포지토리 등록

```jsx
sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"
```

### Docker 패키지 설치

```jsx
sudo apt-get -y install docker-ce docker-ce-cli containerd.io
```

### Docker-compose 설치

```jsx
sudo curl -L "https://github.com/docker/compose/releases/download/v2.21.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
```

# 배포 후 관리

## 컨테이너 관리

### 전체 컨테이너의 상태 확인 방법

```jsx
docker ps -a
```

### backend 컨테이너 로그 확인

100개까지 끊어서 최신 로그 계속 확인 가능

로그를 리눅스에서 보는것이 불편하다면 docker cp, scp 명령어를 활용하여 작업 PC로 로그파일을 복사해와서 보는것도 좋은 방법이다.

```jsx
docker logs backend logs --tail 100 -f
```

### HostOS → backend 컨테이너로 파일 전송

HostOS 위치에서

```jsx
docker cp {fileName} backend:{path}
```

### backend 컨테이너 → HostOS로 파일 전송

HostOS 위치에서

```jsx
docker cp backend:{fileName} {path} 
```

### 실행중인 컨테이너로 접속하기

```jsx
docker exec -it {containerName} /bin/bash
```

### 컨테이너 중지하기

```jsx
docker stop {containerName}
```

### 컨테이너 실행하기

```jsx
docker start {containerName}
```

## 수동 배포하기

개발 중 Jenkins 배포를 통해 서버에 빌드파일을 업로드 하지 않고 수동으로 배포했던 방법

## frontend

로컬 레포지토리의 frontend 경로로 이동

```jsx
cd S10P12A802/frontend
```

빌드 수행

```jsx
npm run build
```

frontend의 dist 폴더의 내용을 호스트 OS의 location root 디렉토리로 복사

```jsx
scp -i I10A802T.pem -r {fileName} [ubuntu@i10a802.p.ssafy.io](mailto:ubuntu@i10a101.p.ssafy.io):/usr/share/nginx/html 
```

파일이 업로드되면 바로 서버 접속 시 변경된 빌드 파일로 접근 가능